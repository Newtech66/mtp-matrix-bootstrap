{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ff1ab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sympy.matrices import Matrix\n",
    "from collections import Counter\n",
    "import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2c29265",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiteBasis:\n",
    "    def __init__(self, N):\n",
    "        self._N = N\n",
    "        self._ops = self.gen_basis()\n",
    "        self._ops.sort()\n",
    "        self._opset = set(self._ops)\n",
    "   \n",
    "    def full_rank(self, word):\n",
    "        r = 0\n",
    "        for i, op in enumerate(reversed(word)):\n",
    "            if op not in 'IXYZ':\n",
    "                raise ValueError(f'{word} must have only IXYZ')\n",
    "            r += (4 ** i) * ('IXYZ'.find(op))\n",
    "        return r\n",
    "\n",
    "    def full_unrank(self, pos):\n",
    "        word = [None] * self._N\n",
    "        for i in range(self._N):\n",
    "            word[i] = 'IXYZ'[pos % 4]\n",
    "            pos //= 4\n",
    "        return ''.join(word[::-1])\n",
    "\n",
    "    def enforce_rotation(self):\n",
    "        exclude = set()\n",
    "        L = self._N\n",
    "        for i in range(4 ** L):\n",
    "            if i in exclude:\n",
    "                continue\n",
    "            op = self.full_unrank(i)\n",
    "            op2 = op\n",
    "            for j in range(L - 1):\n",
    "                op = op[1:] + op[0]\n",
    "                if op == op2:\n",
    "                    break\n",
    "                exclude.add(self.full_rank(op))\n",
    "        small_basis = []\n",
    "        for i in range(4 ** L):\n",
    "            if i in exclude:\n",
    "                continue\n",
    "            small_basis.append(self.full_unrank(i))\n",
    "        return small_basis\n",
    "\n",
    "    def enforce_reflection(self, basis):\n",
    "        exclude = set()\n",
    "        bset = set(basis)\n",
    "        for word in bset:\n",
    "            if word in exclude:\n",
    "                continue\n",
    "            rword = word[::-1]\n",
    "            if word == rword:\n",
    "                continue\n",
    "            if rword not in bset:\n",
    "                rword2 = rword[1:] + rword[0]\n",
    "                while rword2 not in bset:\n",
    "                    if rword2 == rword:\n",
    "                        break\n",
    "                    rword2 = rword2[1:] + rword2[0]\n",
    "                if word != rword2:\n",
    "                    exclude.add(rword2)\n",
    "            else:\n",
    "                exclude.add(rword)\n",
    "        smaller_basis = []\n",
    "        for word in basis:\n",
    "            if word in exclude:\n",
    "                continue\n",
    "            smaller_basis.append(word)\n",
    "        return smaller_basis\n",
    "\n",
    "    def gen_basis(self):\n",
    "        small_basis = []\n",
    "        L = self._N\n",
    "        for i in range(4 ** L):\n",
    "            small_basis.append(self.full_unrank(i))\n",
    "        return small_basis\n",
    "        # small_basis = self.enforce_rotation()\n",
    "        # return self.enforce_reflection(small_basis)\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self._ops)\n",
    "    \n",
    "    def rank(self, word: str):\n",
    "        if len(word) != self._N:\n",
    "            raise ValueError(f'{word} must be of length {self._N}')\n",
    "        word = self.normalize(word)\n",
    "        return self._ops.index(word)\n",
    "        # return bisect.bisect_left(self._ops, word)\n",
    "\n",
    "    def unrank(self, pos: int):\n",
    "        # word = self.full_unrank(pos)\n",
    "        # return self._ops[self.rank(word)]\n",
    "        return self._ops[pos]\n",
    "\n",
    "    def normalize(self, word):\n",
    "        if len(word) != self._N:\n",
    "            raise ValueError(f'{word} must be of length {self._N}')\n",
    "        if word not in self._opset:\n",
    "            word2 = word[1:] + word[0]\n",
    "            while word2 not in self._opset:\n",
    "                if word2 == word:\n",
    "                    return self.normalize(word[::-1])\n",
    "                word2 = word2[1:] + word2[0]\n",
    "            return word2\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b681fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basis_commutator(o1, o2):\n",
    "    commutation_table = [\n",
    "        [(0, ''),(0, ''),(0, ''),(0, '')],\n",
    "        [(0, ''),(0, ''),(2, 'Z'),(-2, 'Y')],\n",
    "        [(0, ''),(-2, 'Z'),(0, ''),(2, 'X')],\n",
    "        [(0, ''),(2, 'Y'),(-2, 'X'),(0, '')],\n",
    "    ] # everything here must be multiplied with 1j\n",
    "    return commutation_table['IXYZ'.find(o1)]['IXYZ'.find(o2)]\n",
    "\n",
    "def basis_anticommutator(o1, o2):\n",
    "    anticommutation_table = [\n",
    "        [(2, 'I'),(2, 'X'),(2, 'Y'),(2, 'Z')],\n",
    "        [(2, 'X'),(2, 'I'),(0, ''),(0, '')],\n",
    "        [(2, 'Y'),(0, ''),(2, 'I'),(0, '')],\n",
    "        [(2, 'Z'),(0, ''),(0, ''),(2, 'I')],\n",
    "    ]\n",
    "    return anticommutation_table['IXYZ'.find(o1)]['IXYZ'.find(o2)]\n",
    "\n",
    "def basis_product(o1, o2):\n",
    "    product_table = [\n",
    "        [(1, 'I'),(1, 'X'),(1, 'Y'),(1, 'Z')],\n",
    "        [(1, 'X'),(1, 'I'),(1j, 'Z'),(-1j, 'Y')],\n",
    "        [(1, 'Y'),(-1j, 'Z'),(1, 'I'),(1j, 'X')],\n",
    "        [(1, 'Z'),(1j, 'Y'),(-1j, 'X'),(1, 'I')],\n",
    "    ]\n",
    "    return product_table['IXYZ'.find(o1)]['IXYZ'.find(o2)]\n",
    "\n",
    "def anticommutator(word1, word2):\n",
    "    if len(word1) != len(word2):\n",
    "        raise ValueError(f'{word1} and {word2} do not have same length')\n",
    "    if len(word1) == 1:\n",
    "        c, o = basis_anticommutator(word1, word2)\n",
    "        return Counter({o: c})\n",
    "    expression = Counter()\n",
    "    e_1 = commutator(word1[0], word2[0])\n",
    "    e_2 = commutator(word1[1:], word2[1:])\n",
    "    e_3 = anticommutator(word1[0], word2[0])\n",
    "    e_4 = anticommutator(word1[1:], word2[1:])\n",
    "    for o1, c1 in e_1.items():\n",
    "        for o2, c2 in e_2.items():\n",
    "            expression[o1 + o2] -= 0.5 * c1 * c2 # since c1 * 1j * c2 * 1j = - c1 * c2\n",
    "    for o1, c1 in e_3.items():\n",
    "        for o2, c2 in e_4.items():\n",
    "            expression[o1 + o2] += 0.5 * c1 * c2\n",
    "    return expression\n",
    "\n",
    "def commutator(word1: str, word2: str):\n",
    "    if len(word1) != len(word2):\n",
    "        raise ValueError(f'{word1} and {word2} do not have same length')\n",
    "    if len(word1) == 1:\n",
    "        c, o = basis_commutator(word1, word2)\n",
    "        return Counter({o: c})\n",
    "    expression = Counter()\n",
    "    e_1 = commutator(word1[0], word2[0])\n",
    "    e_2 = anticommutator(word1[1:], word2[1:])\n",
    "    e_3 = anticommutator(word1[0], word2[0])\n",
    "    e_4 = commutator(word1[1:], word2[1:])\n",
    "    for o1, c1 in e_1.items():\n",
    "        for o2, c2 in e_2.items():\n",
    "            expression[o1 + o2] += 0.5 * c1 * c2\n",
    "    for o1, c1 in e_3.items():\n",
    "        for o2, c2 in e_4.items():\n",
    "            expression[o1 + o2] += 0.5 * c1 * c2\n",
    "    # whatever is returned, needs to be multiplied by 1j\n",
    "    return expression\n",
    "\n",
    "def product(word1, word2):\n",
    "    if len(word1) != len(word2):\n",
    "        raise ValueError(f'{word1} and {word2} do not have same length')\n",
    "    word = []\n",
    "    coeff = 1\n",
    "    for o1, o2 in zip(word1, word2):\n",
    "        c, op = basis_product(o1, o2)\n",
    "        word.append(op)\n",
    "        coeff *= c\n",
    "    # coeff can be real or complex\n",
    "    return (coeff, ''.join(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1fc41f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasisReduction():\n",
    "    def __init__(self, A, b):\n",
    "        self._A = A.copy()\n",
    "        self._b = b.copy()\n",
    "        self._Arref, self._brref = Matrix(A).rref_rhs(Matrix(b))\n",
    "        self._pivots = Matrix(A).rref()[1]\n",
    "        self._free = sorted(list(set(range(A.shape[1])) - set(self._pivots))) # This is with the original numbering\n",
    "        self._sz = len(self._free)\n",
    "        self._reductions = [[Counter(), 0.0] for _ in range(A.shape[1])]\n",
    "        self._init_free() # Initialize mappings for free variables\n",
    "        self._generate_reductions() # Initialize mappings for pivot variables\n",
    "\n",
    "    def _init_free(self):\n",
    "        for i, p in enumerate(self._free):\n",
    "            self._reductions[p][0][i] += 1.0\n",
    "            self._reductions[p][1] = 0.0\n",
    "    \n",
    "    def _generate_reductions(self):\n",
    "        crow = len(self._pivots) - 1\n",
    "        for pcol in reversed(self._pivots):\n",
    "            # Create mapping\n",
    "            self._reductions[pcol][1] += np.double(self._brref[crow])\n",
    "            for ccol in range(pcol + 1, self._A.shape[1]):\n",
    "                if not np.isclose(self._Arref[crow, ccol], 0.0):\n",
    "                    coeff = np.double(-self._Arref[crow, ccol]) # minus sign to transfer to other side of equality\n",
    "                    self._reductions[pcol][1] += coeff * self._reductions[ccol][1]\n",
    "                    for freew, c in self._reductions[ccol][0].items():\n",
    "                        self._reductions[pcol][0][freew] += coeff * c\n",
    "            # Update currow\n",
    "            crow -= 1\n",
    "\n",
    "    def size(self):\n",
    "        return self._sz\n",
    "\n",
    "    def reduce(self, p):\n",
    "        # Return a mapping of the p-th element of the original basis\n",
    "        # to a linear combination + constant offset of the new basis\n",
    "        # Remember to take care of the numbering\n",
    "        return self._reductions[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cf14bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schwinger_dyson(basis, n, hamil: list, word1: str):\n",
    "    C = np.zeros((1, n))\n",
    "    expression = Counter()\n",
    "    for coeff, w in hamil:\n",
    "        terms = commutator(w, word1)\n",
    "        for op, c in terms.items():\n",
    "            if len(op) != len(word1):\n",
    "                continue\n",
    "            expression[op] += coeff * c\n",
    "    for op, c in expression.items():\n",
    "        C[0, basis.rank(op)] += c\n",
    "    return C\n",
    "\n",
    "def construct_hamil(L, h):\n",
    "    hamil = []\n",
    "    for i in range(L):\n",
    "        t1 = None\n",
    "        if i<L-1:\n",
    "            t1 = 'I'*i + 'XX' + 'I'*(L-i-2)\n",
    "        else:\n",
    "            t1 = 'X' + 'I'*(L-2) + 'X'\n",
    "        t2 = 'I'*i+'Z'+'I'*(L-i-1)\n",
    "        hamil.extend([(-1, t1), (-h, t2)])\n",
    "    if L == 2:\n",
    "        hamil = [(-h, 'IZ'), (-h, 'ZI'), (-1, 'XX')]\n",
    "    return hamil\n",
    "\n",
    "def construct_lin(L, basis, hamil):\n",
    "    n = basis.size()\n",
    "    cons = [np.zeros((1, n))]\n",
    "    cons[0][0, basis.rank('I' * L)] = 1.0\n",
    "    for i in range(1, n):\n",
    "        cons.append(schwinger_dyson(basis, n, hamil, basis.unrank(i)))\n",
    "    A = np.vstack(cons)\n",
    "    b = np.zeros((A.shape[0], 1))\n",
    "    b[0, 0] = 1.0 # Normalization\n",
    "    return A, b\n",
    "\n",
    "# Remember that all expectation values are real in the Ising model\n",
    "def create_problem(L):\n",
    "    basis = SiteBasis(L)\n",
    "    n = basis.size()\n",
    "    H = construct_hamil(L, 1)\n",
    "    A, b = construct_lin(L, basis, H)\n",
    "    redbas = BasisReduction(A, b)\n",
    "    c = np.zeros((redbas.size(), 1))\n",
    "    offset = 0\n",
    "    for coeff, word in H:\n",
    "        # rew will be a dict with mapping {rank in reduced basis: coefficient}\n",
    "        p2 = basis.rank(word)\n",
    "        rew, const = redbas.reduce(p2)\n",
    "        offset += coeff * const\n",
    "        for p, c2 in rew.items():\n",
    "            c[p, 0] += coeff * c2\n",
    "    return A, b, c, offset, redbas, basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f240ea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 3\n",
    "A, b, c, offset, redbas, basis = create_problem(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "756a9ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IZZ\n",
      "YXI\n",
      "YYZ\n",
      "YZY\n",
      "ZII\n",
      "ZIX\n",
      "ZIZ\n",
      "ZXI\n",
      "ZXX\n",
      "ZYX\n",
      "ZYY\n",
      "ZYZ\n",
      "ZZI\n",
      "ZZY\n",
      "ZZZ\n"
     ]
    }
   ],
   "source": [
    "for i in redbas._free:\n",
    "    print(basis.unrank(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
